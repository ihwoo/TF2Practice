{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 4]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 4]]\n",
      "Box(4, 4)\n",
      "Discrete(4)\n",
      "[[4 0 2 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [4 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gym_2048/env.py:120: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  board[tile_locs] = tiles\n"
     ]
    }
   ],
   "source": [
    "import gym_2048\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "env=gym.make('2048-v0')\n",
    "obs=env.reset()\n",
    "print(obs)\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "obs,reward,done,info=env.step(0)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score>656\tsteps>89\n",
      "[[ 4 16  8  2]\n",
      " [64  4 32  8]\n",
      " [ 4 32  2  4]\n",
      " [ 8  2  4  2]]\n"
     ]
    }
   ],
   "source": [
    "#Random Agent \n",
    "score=0\n",
    "step=0\n",
    "obs=env.reset()\n",
    "while True:\n",
    "    action=env.action_space.sample()\n",
    "    obs,reward,done,info=env.step(action)\n",
    "    score+=reward\n",
    "    step+=1\n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "print(f'score>{score}\\tsteps>{step}')\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 4: 2, 8: 3, 16: 4, 32: 5, 64: 6, 128: 7, 256: 8, 512: 9, 1024: 10, 2048: 11}\n"
     ]
    }
   ],
   "source": [
    "layer_count=12 # 0,2,4,8,16,32,64,128,256,512,1024,2048\n",
    "table={2**i:i for i in range(layer_count)}\n",
    "print(table)\n",
    "\n",
    "def preprocess(obs):\n",
    "    x=np.zeros((4,4,layer_count))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if obs[i,j]>0:\n",
    "                v=min(obs[i,j], 2**(layer_count-1))\n",
    "                x[i,j,table[v]]=1\n",
    "            else:\n",
    "                x[i,j,0]=1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    dense1=128\n",
    "    dense2=128\n",
    "    x=tf.keras.Input(shape=(4,4,layer_count))\n",
    "    conv_a=tf.keras.layers.Conv2D(dense1,kernel_size=(2,1),activation='relu')(x)\n",
    "    conv_b=tf.keras.layers.Conv2D(dense1,kernel_size=(1,2),activation='relu')(x)\n",
    "    conv_aa=tf.keras.layers.Conv2D(dense2,kernel_size=(2,1),activation='relu')(conv_a)\n",
    "    conv_ab=tf.keras.layers.Conv2D(dense2,kernel_size=(1,2),activation='relu')(conv_a)\n",
    "    conv_ba=tf.keras.layers.Conv2D(dense2,kernel_size=(2,1),activation='relu')(conv_b)\n",
    "    conv_bb=tf.keras.layers.Conv2D(dense2,kernel_size=(1,2),activation='relu')(conv_b)\n",
    "    flat=[tf.keras.layers.Flatten()(a) for a in [conv_a,conv_b,conv_aa,conv_ab,conv_ba,conv_bb]]\n",
    "    concat=tf.keras.layers.Concatenate()(flat)\n",
    "    dense1=tf.keras.layers.Dense(256,activation='relu')(concat)\n",
    "    out=tf.keras.layers.Dense(4,activation='linear')(dense1)\n",
    "    model=tf.keras.Model(inputs=x,outputs=out)\n",
    "    model.compile(optimizer=tf.optimizers.RMSprop(learning_rate=0.0005),loss='mse')\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 4, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 3, 4, 128)    3200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 4, 3, 128)    3200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 2, 4, 128)    32896       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 3, 3, 128)    32896       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 128)    32896       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 4, 2, 128)    32896       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1536)         0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1536)         0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1024)         0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1152)         0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1152)         0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1024)         0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 7424)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          1900800     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            1028        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,039,812\n",
      "Trainable params: 2,039,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=build_model()\n",
    "model.summary()\n",
    "target_model=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma=0.9\n",
    "batch_size=512\n",
    "max_memory=batch_size*8\n",
    "memory=[]\n",
    "\n",
    "def append_sample(state,action,reward,next_state,done):\n",
    "    memory.append([state,action,reward,next_state,done])\n",
    "    \n",
    "def train_model():\n",
    "    np.random.shuffle(memory)\n",
    "    \n",
    "    len=max_memory//batch_size\n",
    "    for k in range(len):\n",
    "        mini_batch=memory[k*batch_size:(k+1)*batch_size]\n",
    "        \n",
    "        states=np.zeros((batch_size,4,4,layer_count))\n",
    "        next_states=np.zeros((batch_size,4,4,layer_count))\n",
    "        actions,rewards,dones=[],[],[]\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            states[i]=mini_batch[i][0]\n",
    "            actions.append(mini_batch[i][1])\n",
    "            rewards.append(mini_batch[i][2])\n",
    "            next_states[i]=mini_batch[i][3]\n",
    "            dones.append(mini_batch[i][4])\n",
    "            \n",
    "        target=model.predict(states)\n",
    "        next_target=target_model.predict(next_states)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            if dones[i]:\n",
    "                target[i][actions[i]]=rewards[i]\n",
    "            else:\n",
    "                target[i][actions[i]]=rewards[i]+gamma*np.amax(next_target[i])\n",
    "        model.fit(states,target,batch_size=batch_size,epochs=2,verbose=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\tscore mean>856.28\tstep mean>104.97\titeration>10497\tepsilon>0.8822227695311732\n",
      "200\tscore mean>991.6\tstep mean>116.08\titeration>22105\tepsilon>0.8647966834213929\n",
      "300\tscore mean>1013.0\tstep mean>117.76\titeration>33881\tepsilon>0.8434973191038082\n",
      "400\tscore mean>980.88\tstep mean>114.53\titeration>45334\tepsilon>0.822722543893733\n",
      "500\tscore mean>917.96\tstep mean>110.15\titeration>56349\tepsilon>0.8064717346996236\n",
      "600\tscore mean>1013.36\tstep mean>115.42\titeration>67891\tepsilon>0.7866088748870222\n",
      "700\tscore mean>1047.4\tstep mean>119.44\titeration>79835\tepsilon>0.7710714001562543\n",
      "800\tscore mean>964.68\tstep mean>113.68\titeration>91203\tepsilon>0.7520804269233059\n",
      "900\tscore mean>1006.4\tstep mean>117.39\titeration>102942\tepsilon>0.7335571886682876\n",
      "1000\tscore mean>1138.2\tstep mean>125.54\titeration>115496\tepsilon>0.7154901653913079\n",
      "1100\tscore mean>1047.48\tstep mean>117.96\titeration>127292\tepsilon>0.7013574614264854\n",
      "1200\tscore mean>1057.64\tstep mean>119.87\titeration>139279\tepsilon>0.6840834959104777\n",
      "1300\tscore mean>1016.0\tstep mean>115.67\titeration>150846\tepsilon>0.6672349766199102\n",
      "1400\tscore mean>1042.48\tstep mean>117.74\titeration>162620\tepsilon>0.6540554322240942\n",
      "1500\tscore mean>1033.84\tstep mean>117.09\titeration>174329\tepsilon>0.6411362164929434\n",
      "1600\tscore mean>1038.04\tstep mean>117.68\titeration>186097\tepsilon>0.6253454599902072\n",
      "1700\tscore mean>1201.04\tstep mean>128.52\titeration>198949\tepsilon>0.6099436192662311\n",
      "1800\tscore mean>1203.0\tstep mean>129.27\titeration>211876\tepsilon>0.59492111558532\n",
      "1900\tscore mean>1308.84\tstep mean>136.22\titeration>225498\tepsilon>0.5773816976414295\n",
      "2000\tscore mean>1141.84\tstep mean>125.73\titeration>238071\tepsilon>0.5631611723270674\n",
      "2100\tscore mean>1262.72\tstep mean>132.95\titeration>251366\tepsilon>0.5492908890467747\n",
      "2200\tscore mean>1420.16\tstep mean>144.43\titeration>265809\tepsilon>0.5330967378839205\n",
      "2300\tscore mean>1463.44\tstep mean>147.74\titeration>280583\tepsilon>0.5173800214229971\n",
      "2400\tscore mean>1541.4\tstep mean>152.69\titeration>295852\tepsilon>0.5021266639713475\n",
      "2500\tscore mean>1602.28\tstep mean>156.94\titeration>311546\tepsilon>0.4873230048147885\n",
      "2600\tscore mean>1518.88\tstep mean>150.8\titeration>326626\tepsilon>0.4729557859832469\n",
      "2700\tscore mean>1649.2\tstep mean>159.7\titeration>342596\tepsilon>0.4567284978876515\n",
      "2800\tscore mean>1639.0\tstep mean>159.11\titeration>358507\tepsilon>0.44326326392389254\n",
      "2900\tscore mean>1815.52\tstep mean>170.72\titeration>375579\tepsilon>0.4301950109379734\n",
      "3000\tscore mean>1805.24\tstep mean>170.12\titeration>392591\tepsilon>0.41543486086334136\n",
      "3100\tscore mean>1911.6\tstep mean>177.45\titeration>410336\tepsilon>0.40118113700167407\n",
      "3200\tscore mean>2043.68\tstep mean>183.37\titeration>428673\tepsilon>0.38741646368213617\n",
      "3300\tscore mean>1714.72\tstep mean>165.23\titeration>445196\tepsilon>0.37412406139959065\n",
      "3400\tscore mean>1974.0\tstep mean>180.82\titeration>463278\tepsilon>0.3612877263599334\n",
      "3500\tscore mean>1997.6\tstep mean>182.36\titeration>481514\tepsilon>0.34889181072723424\n",
      "3600\tscore mean>2056.96\tstep mean>186.36\titeration>500150\tepsilon>0.33524497865532943\n",
      "3700\tscore mean>2043.2\tstep mean>185.79\titeration>518729\tepsilon>0.32374259933686506\n",
      "3800\tscore mean>2233.92\tstep mean>196.41\titeration>538370\tepsilon>0.3110794735430463\n",
      "3900\tscore mean>2052.48\tstep mean>185.82\titeration>556952\tepsilon>0.3004062216505576\n",
      "4000\tscore mean>2380.52\tstep mean>206.88\titeration>577640\tepsilon>0.2872197945412427\n",
      "4100\tscore mean>2169.68\tstep mean>193.8\titeration>597020\tepsilon>0.2773651770676686\n",
      "4200\tscore mean>2242.92\tstep mean>197.89\titeration>616809\tepsilon>0.26651609469411913\n",
      "4300\tscore mean>2597.2\tstep mean>219.38\titeration>638747\tepsilon>0.25481728553885685\n",
      "4400\tscore mean>2564.88\tstep mean>217.66\titeration>660513\tepsilon>0.24363199935040966\n",
      "4500\tscore mean>2480.88\tstep mean>211.66\titeration>681679\tepsilon>0.23410238334839692\n",
      "4600\tscore mean>2686.4\tstep mean>224.76\titeration>704155\tepsilon>0.22382638441209202\n",
      "4700\tscore mean>2910.56\tstep mean>238.68\titeration>728023\tepsilon>0.21293676988389065\n",
      "4800\tscore mean>3117.32\tstep mean>251.26\titeration>753149\tepsilon>0.20257695752751229\n",
      "4900\tscore mean>2274.88\tstep mean>200.53\titeration>773202\tepsilon>0.1946532011193211\n",
      "5000\tscore mean>1966.16\tstep mean>180.04\titeration>791206\tepsilon>0.18891445062096482\n",
      "5100\tscore mean>1990.44\tstep mean>181.56\titeration>809362\tepsilon>0.1824327258879131\n",
      "5200\tscore mean>1222.4\tstep mean>132.25\titeration>822587\tepsilon>0.1770542584875029\n",
      "5300\tscore mean>1358.2\tstep mean>140.76\titeration>836663\tepsilon>0.17269353043685245\n",
      "5400\tscore mean>1527.36\tstep mean>151.57\titeration>851820\tepsilon>0.1676021932373687\n",
      "5500\tscore mean>1606.92\tstep mean>157.2\titeration>867540\tepsilon>0.16185169994450774\n",
      "5600\tscore mean>1654.72\tstep mean>160.43\titeration>883583\tepsilon>0.1570800007462654\n",
      "5700\tscore mean>1633.96\tstep mean>160.12\titeration>899595\tepsilon>0.15244898041173793\n",
      "5800\tscore mean>1719.6\tstep mean>165.73\titeration>916168\tepsilon>0.1472183994603323\n",
      "5900\tscore mean>1765.24\tstep mean>171.67\titeration>933335\tepsilon>0.142878118086011\n",
      "6000\tscore mean>1658.88\tstep mean>162.68\titeration>949603\tepsilon>0.13866579654875724\n",
      "6100\tscore mean>1505.16\tstep mean>152.53\titeration>964856\tepsilon>0.13457766234663154\n",
      "6200\tscore mean>1634.48\tstep mean>161.28\titeration>980984\tepsilon>0.1299602529336343\n",
      "6300\tscore mean>1724.04\tstep mean>166.75\titeration>997659\tepsilon>0.12550126854686705\n",
      "6400\tscore mean>1655.68\tstep mean>164.12\titeration>1014071\tepsilon>0.12180124993285932\n",
      "6500\tscore mean>1785.36\tstep mean>171.12\titeration>1031183\tepsilon>0.11762220395934384\n",
      "6600\tscore mean>1853.2\tstep mean>176.14\titeration>1048797\tepsilon>0.11358654260017662\n",
      "6700\tscore mean>1791.88\tstep mean>170.01\titeration>1065798\tepsilon>0.1096893462761613\n",
      "6800\tscore mean>1922.4\tstep mean>181.02\titeration>1083900\tepsilon>0.10592586420068491\n",
      "6900\tscore mean>1650.0\tstep mean>161.98\titeration>1100098\tepsilon>0.10229150858838183\n",
      "7000\tscore mean>1728.32\tstep mean>168.97\titeration>1116995\tepsilon>0.09927575830781311\n",
      "7100\tscore mean>1670.28\tstep mean>162.56\titeration>1133251\tepsilon>0.09586957029042696\n",
      "7200\tscore mean>1791.72\tstep mean>172.31\titeration>1150482\tepsilon>0.09258024984481811\n",
      "7300\tscore mean>1928.52\tstep mean>180.78\titeration>1168560\tepsilon>0.08940378720133693\n",
      "7400\tscore mean>1942.12\tstep mean>181.28\titeration>1186688\tepsilon>0.08633631016701476\n",
      "7500\tscore mean>1779.12\tstep mean>171.69\titeration>1203857\tepsilon>0.08337407940525712\n",
      "7600\tscore mean>2009.0\tstep mean>184.42\titeration>1222299\tepsilon>0.08051348387749235\n",
      "7700\tscore mean>1896.16\tstep mean>178.19\titeration>1240118\tepsilon>0.07736421536439685\n",
      "7800\tscore mean>1845.44\tstep mean>177.51\titeration>1257869\tepsilon>0.07470982049660209\n",
      "7900\tscore mean>1801.6\tstep mean>172.7\titeration>1275139\tepsilon>0.07214649889932379\n",
      "8000\tscore mean>1155.0\tstep mean>130.04\titeration>1288143\tepsilon>0.07036957885123181\n",
      "8100\tscore mean>943.2\tstep mean>117.4\titeration>1299883\tepsilon>0.06932450329844486\n",
      "8200\tscore mean>1143.84\tstep mean>131.93\titeration>1313076\tepsilon>0.06728068369740793\n",
      "8300\tscore mean>1503.72\tstep mean>157.93\titeration>1328869\tepsilon>0.06529711982649285\n",
      "8400\tscore mean>1486.72\tstep mean>159.54\titeration>1344823\tepsilon>0.0636888954071171\n",
      "8500\tscore mean>1626.44\tstep mean>172.85\titeration>1362108\tepsilon>0.06181122435852588\n",
      "8600\tscore mean>1369.8\tstep mean>157.58\titeration>1377866\tepsilon>0.05998891066138784\n",
      "8700\tscore mean>1196.0\tstep mean>144.58\titeration>1392324\tepsilon>0.05851142388595656\n",
      "8800\tscore mean>1555.32\tstep mean>163.34\titeration>1408658\tepsilon>0.05650387527270299\n",
      "8900\tscore mean>1347.6\tstep mean>144.1\titeration>1423068\tepsilon>0.05483803242750099\n",
      "9000\tscore mean>1454.88\tstep mean>154.04\titeration>1438472\tepsilon>0.05322130183117604\n",
      "9100\tscore mean>1380.36\tstep mean>151.96\titeration>1453668\tepsilon>0.051652235560236015\n",
      "9200\tscore mean>1074.44\tstep mean>133.76\titeration>1467044\tepsilon>0.05038007552065005\n",
      "9300\tscore mean>1332.12\tstep mean>150.77\titeration>1482121\tepsilon>0.04913924793257883\n",
      "9400\tscore mean>982.56\tstep mean>124.42\titeration>1494563\tepsilon>0.04816862600417631\n",
      "9500\tscore mean>970.68\tstep mean>126.78\titeration>1507241\tepsilon>0.0472171762643508\n",
      "9600\tscore mean>1336.88\tstep mean>149.41\titeration>1522182\tepsilon>0.046054248771008444\n",
      "9700\tscore mean>1098.76\tstep mean>135.86\titeration>1535768\tepsilon>0.04491996340457347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9800\tscore mean>1616.72\tstep mean>175.23\titeration>1553291\tepsilon>0.043378742831715444\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math \n",
    "\n",
    "def softmax(logits):\n",
    "    exp_logits=np.exp(logits-np.max(logits))\n",
    "    sum_exp_logits=np.sum(exp_logits)\n",
    "    return exp_logits/sum_exp_logits\n",
    "max_episodes=10001\n",
    "epsilon=0.9\n",
    "epsilon_min=0.1\n",
    "\n",
    "scores=[]\n",
    "steps=[]\n",
    "iteration=0\n",
    "train_count=0\n",
    "\n",
    "for i in range(max_episodes):\n",
    "    if i%100==0 and i!=0:\n",
    "        print(f'{i}\\tscore mean>{np.mean(scores[-100:])}\\tstep mean>{np.mean(steps[-100:])}\\titeration>{iteration}\\tepsilon>{epsilon}')\n",
    "    prev_obs=env.reset()\n",
    "    score=0\n",
    "    step=0\n",
    "    not_move_list=np.array([1,1,1,1])\n",
    "    prev_max=np.max(prev_obs)\n",
    "    \n",
    "    while True:\n",
    "        iteration+=1\n",
    "        if random.random()<epsilon:\n",
    "            action=env.action_space.sample()\n",
    "        else:\n",
    "            x=preprocess(prev_obs)\n",
    "            logits=model.predict(np.expand_dims(x,axis=0))[0]\n",
    "            prob=softmax(logits)\n",
    "            prob=prob*not_move_list\n",
    "            action=np.argmax(prob)\n",
    "        obs,reward,done,info=env.step(action)\n",
    "        score+=reward\n",
    "        step+=1\n",
    "        #not move situation\n",
    "        if reward==0 and np.array_equal(obs,prev_obs):\n",
    "            not_move_list[action]=0\n",
    "            continue\n",
    "        else:\n",
    "            not_move_list=np.array([1,1,1,1])\n",
    "        \n",
    "        #custom reward\n",
    "        now_max=np.max(obs)\n",
    "        if prev_max<now_max:\n",
    "            prev_max=now_max\n",
    "            reward=math.log(now_max,2)*0.1\n",
    "        else:\n",
    "            reward=0\n",
    "        reward+=np.count_nonzero(prev_obs)-np.count_nonzero(obs)+1\n",
    "        append_sample(preprocess(prev_obs),action,reward,preprocess(obs),done)\n",
    "        \n",
    "        if len(memory)>=max_memory:\n",
    "            train_model()\n",
    "            memory=[]\n",
    "            train_count+=1\n",
    "            if train_count%4==0:\n",
    "                target_model.set_weights(model.get_weights())\n",
    "        prev_obs=obs\n",
    "        if epsilon>0.01 and iteration%2500==0:\n",
    "            epsilon=epsilon/1.005\n",
    "        if done:\n",
    "            break\n",
    "    scores.append(score)\n",
    "    steps.append(step)\n",
    "    #print(f'{i}\\tScore>{score}\\tStep>{step}\\tMax_tile>{np.max(obs)}\\tmemory_len>{len(memory)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "N=100\n",
    "rolling_mean=[np.mean(scores[x:x+N]) for x in range(len(scores)-N+1)]\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(range(len(scores)),scores,marker='.')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(rolling_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('DQN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
